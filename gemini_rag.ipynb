{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('DL 1.pdf')\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'DL 1.pdf', 'page': 0}, page_content='Deep Learning\\nDnyanesh Sarode'),\n",
       " Document(metadata={'source': 'DL 1.pdf', 'page': 1}, page_content='Topics \\n•History of AI\\n•Type of Data\\n•Deep Learning and Its Applications\\n•Benefits of Deep Learning over Machine Learning\\n•Biological Neuron\\n•Perceptron : Structure\\n•Structure of Neural Network\\n•Optimizers'),\n",
       " Document(metadata={'source': 'DL 1.pdf', 'page': 2}, page_content='•1943: \\nAlan Turing publishes a paper titled \"Computing Machinery and Intelligence\" in which he proposes the Turing test \\nas a way to measure a machine\\'s intelligence.\\n•1950: \\nJohn McCarthy coins the term \"artificial intelligence\" at a Dartmouth conference.\\n•1956: \\nThe Dartmouth conference is held, which is considered to be the start of the modern era of AI research.\\n•1957: \\nFrank Rosenblatt develops the perceptron, a neural network that can learn to classify patterns.\\n•1966: \\nMarvin Minsky and Seymour Papert publish the book \"Perceptrons\", which criticizes the perceptron and argues \\nthat it is not capable of general intelligence.\\n•1970s: \\nThe AI winter begins, a period of pessimism in AI research due to the failure of the perceptron and other early AI \\nsystems\\n'),\n",
       " Document(metadata={'source': 'DL 1.pdf', 'page': 3}, page_content='•1980s: \\nThe AI winter ends, and there is a renewed interest in AI research.\\n•1986: \\nGeoffrey Hinton, David Rumelhart, and Ronald Williams develop backpropagation, a method for training neural \\nnetworks\\n•1990s:\\nDeep learning becomes a popular research area in AI.\\n•2000s: \\nDeep learning achieves significant results in image recognition, speech recognition, and natural language \\nprocessing.\\n•2010s: \\nDeep learning continues to achieve breakthroughs in a wide range of applications, including self-driving cars, \\nmedical diagnosis, and robotics.\\n•2020s: \\nAI is becoming increasingly ubiquitous, with applications in many aspects of our lives.'),\n",
       " Document(metadata={'source': 'DL 1.pdf', 'page': 4}, page_content=\"•2020:\\nCOVID-19 pandemic accelerates AI adoption for contact tracing and remote work. GPT-3 is launched, a large \\nlanguage model that can generate realistic and creative text formats. ChatGPT is launched, a chatbot that can \\ngenerate human-like conversations.\\n•2021:\\nAlphaFold 2 is released, an AI system that can predict the structure of proteins with unprecedented accuracy. \\nSelf-driving cars are developed that can drive without human intervention. AI is used to develop new financial \\nproducts and services. Bard is launched, a large language model from Google AI that can generate text, \\ntranslate languages, write different kinds of creative content, and answer your questions in an informative way.\\n•2022:\\nAI systems are developed that can understand and respond to human emotions. AI is used to create new forms \\nof art and entertainment. AI systems are developed that can learn from their own experiences. ChatGPT is \\nupdated with new capabilities, including the ability to generate different creative text formats, like poems, code, \\nscripts, musical pieces, email, letters, etc.\\n•2023:\\nAI is widely adopted in businesses and governments. AI systems are developed that can interact with the \\nphysical world. AI is used to address some of the world's biggest challenges. Bard is updated with new \\ncapabilities, including the ability to answer your questions in an informative way, even if they are open ended, \\nchallenging, or strange.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "spiliter=RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "doc=spiliter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Gemini Pro\\gemini\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009476273320615292]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
    "sample=embedding.embed_query('Hello')\n",
    "sample[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=Chroma.from_documents(documents=doc,embedding=GoogleGenerativeAIEmbeddings(model='models/embedding-001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(search_type='similarity',search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 16, 'source': 'DL 1.pdf'}, page_content='Gradient Descent\\nw = w - η * ∂J/∂w\\nb = b - η * ∂J/∂b\\nw-weight\\nb-bias\\nη -Learning rate\\n∂J/∂w – Gradient of loss \\nfunction\\nGradient Descent is the iterative Optimization Algorithm'),\n",
       " Document(metadata={'page': 18, 'source': 'DL 1.pdf'}, page_content='Stochastic gradient descent\\n•\\n Stochastic\\n gradient descent is an optimization algorithm that updates the \\nweights and biases of a neural network by minimizing the loss function \\nusing a single data point\\n.\\nThe gradient of the loss function is a vector \\nthat points in the direction of the steepest \\nascent of the loss function. In other words, it is \\nthe direction in which the loss function will \\nincrease most quickly.\\nThe gradient of the loss function can be used \\nto update the weights and biases of a neural \\nnetwork during training. By updating the \\nweights and biases in the direction of the \\nnegative gradient of the loss function, we can \\nmake the neural network more accurate.\\ngradient'),\n",
       " Document(metadata={'page': 20, 'source': 'DL 1.pdf'}, page_content='Minibatch Stochastic gradient descent\\n• Minibatch stochastic gradient descent (SGD) is a machine \\nlearning optimization algorithm that combines the advantages of \\nbatch gradient descent and stochastic gradient descent. It is a \\ntype of stochastic gradient descent that uses a small batch of \\ndata points to calculate the gradient of the loss function.\\n• The size of the minibatch is a hyperparameter that can be tuned \\nto improve the performance of the algorithm. A smaller \\nminibatch size can help to improve the accuracy of the \\nalgorithm, but it can also make the algorithm more \\ncomputationally expensive. A larger minibatch size can make \\nthe algorithm less computationally expensive, but it can also \\nreduce the accuracy of the algorithm.\\nMini-Batch 1\\nMini-Batch 2\\nMini-Batch 3\\nBatch'),\n",
       " Document(metadata={'page': 19, 'source': 'DL 1.pdf'}, page_content=\"w = w - η * ∂J/∂w (for one data point)\\nb = b - η * ∂J/∂b (for one data point)\\nHere, 'w' represents the model's weights, 'b' represents the biases, η is the learning rate, and ∂J/∂w and \\n∂J/∂b are the gradients of the cost function with respect to 'w' and 'b' for the selected data point.\\nStochastic gradient descent\"),\n",
       " Document(metadata={'page': 24, 'source': 'DL 1.pdf'}, page_content='Ada-grad\\n• In traditional gradient descent, the learning rate is a constant \\nvalue. This means that all parameters are updated at the \\nsame rate, regardless of how frequently they are updated. \\nThis can be a problem for parameters that are updated \\nfrequently, as they can become too large and cause the \\nalgorithm to diverge.\\n• Adagrad addresses this problem by maintaining a running \\nsum of the squared gradients for each parameter. The \\nlearning rate for each parameter is then inversely \\nproportional to the square root of this running sum. This \\nmeans that parameters that are updated frequently have a \\nsmaller learning rate, while parameters that are updated \\nless frequently have a larger learning rate.'),\n",
       " Document(metadata={'page': 17, 'source': 'DL 1.pdf'}, page_content=\"Batch gradient descent\\n• Batch gradient descent is an optimization algorithm that updates the \\nweights and biases of a neural network by minimizing the loss function \\nusing the entire training dataset.\\nOptimization refers to the task of \\nminimizing/maximizing an objective function\\nObjective Function : The Function whose value is \\neither maximize or minimized\\nw = w - η * ∂J/∂w\\nb = b - η * ∂J/∂b\\nHere, 'w' represents the model's weights, 'b' represents the biases, η is the learning rate, and ∂J/∂w and ∂J/∂b \\nare the gradients of the cost function with respect to 'w' and 'b', respectively.\"),\n",
       " Document(metadata={'page': 23, 'source': 'DL 1.pdf'}, page_content=\"v_w = β  v_w + η  ∂J/∂w (for a mini-batch)\\nv_b = β  v_b + η  ∂J/∂b (for a mini-batch)\\nw = w - v_w\\nb = b - v_b\\nHere, 'w' represents the model's weights, 'b' represents the biases, η is the learning rate, ∂J/∂w and ∂J/∂b are \\nthe gradients with respect to 'w' and 'b,' and β is the momentum coefficient.\\nMinibatch Stochastic gradient descent with Momentum\"),\n",
       " Document(metadata={'page': 21, 'source': 'DL 1.pdf'}, page_content=\"w = w - η * ∂J/∂w (for a mini-batch)\\nb = b - η * ∂J/∂b (for a mini-batch)\\nHere, 'w' represents the model's weights, 'b' represents the biases, η is the learning rate, and ∂J/∂w and ∂J/∂b \\nare the gradients of the cost function with respect to 'w' and 'b' computed using the mini-batch.\\nMinibatch Stochastic gradient descent\"),\n",
       " Document(metadata={'page': 22, 'source': 'DL 1.pdf'}, page_content='• Minibatch stochastic gradient descent with momentum (SGDM) is an optimization \\nalgorithm that combines the advantages of minibatch stochastic gradient descent and \\nmomentum. Momentum is a technique that helps to accelerate the convergence of the \\nalgorithm.\\n• Momentum is a technique that helps to accelerate the convergence of the algorithm by \\ntaking into account the previous updates to the weights and biases. The momentum term \\nis a vector that is multiplied by the previous update to the weights and biases. This helps \\nto keep the updates in the same direction, which can help the algorithm to converge more \\nquickly.\\nMinibatch Stochastic gradient descent with Momentum'),\n",
       " Document(metadata={'page': 25, 'source': 'DL 1.pdf'}, page_content='RMSprop\\n• RMSprop (Root Mean Squared Propagation) is a type of adaptive learning \\nrate algorithm for stochastic gradient descent. It is similar to AdaGrad, but \\nit uses a decaying average of the squared gradients instead of a running \\nsum. This can help to prevent the learning rate from becoming too small, \\nwhich can happen in AdaGrad when the squared gradients are large.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_doc=retriever.invoke('what is gradient descent ?')\n",
    "retrieve_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch gradient descent\n",
      "• Batch gradient descent is an optimization algorithm that updates the \n",
      "weights and biases of a neural network by minimizing the loss function \n",
      "using the entire training dataset.\n",
      "Optimization refers to the task of \n",
      "minimizing/maximizing an objective function\n",
      "Objective Function : The Function whose value is \n",
      "either maximize or minimized\n",
      "w = w - η * ∂J/∂w\n",
      "b = b - η * ∂J/∂b\n",
      "Here, 'w' represents the model's weights, 'b' represents the biases, η is the learning rate, and ∂J/∂w and ∂J/∂b \n",
      "are the gradients of the cost function with respect to 'w' and 'b', respectively.\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_doc[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model='gemini-1.5-pro',temperature=0.2,max_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=(\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',system_prompt),\n",
    "        ('human',\"{input}\"),\n",
    "    ]\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent is an iterative optimization algorithm used to find the minimum of a function.  It updates the weights and biases of a model by moving in the direction of the negative gradient of the loss function.  This process is repeated until a minimum is reached.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke({'input':'What is gradient Descent?'})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learning rate (η) is a hyperparameter that controls how much the model's weights and biases are adjusted during training.  A smaller learning rate means smaller adjustments and slower learning, while a larger learning rate means larger adjustments and faster but potentially unstable learning.  It determines the step size during gradient descent towards minimizing the loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke({'input':'what is neural learning rate'})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
